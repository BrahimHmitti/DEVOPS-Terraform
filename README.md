# Atelier Terraform âœ de 0 Ã  Terragrunt (sans compte cloud)

Bienvenue ! Cet atelier est conÃ§u pour fonctionner **sans compte chez un CSP** (pas de carte bancaire).
Nous utiliserons uniquement des providers _locaux_ : `random`, `local`, `null`, et `terraform` (pour `terraform_data`).

## PrÃ©-requis
- Terraform â‰¥ 1.6 installÃ© (pour `terraform test`).
- (Optionnel) Terragrunt â‰¥ 0.58 si vous faites l'Ã©tape 4.
- Bash/PowerShell disponibles pour exÃ©cuter quelques scripts locaux.

## Plan
1. **Exercice 1 â€” random_pet & dÃ©pendances**
2. **Exercice 2 â€” Tests & conditions (pre/postconditions, `terraform test`)**
3. **Exercice 3 â€” Modules & dynamic blocks**
4. **Exercice 4 â€” Basculer sur Terragrunt** (selon le modÃ¨le GCP Library)
5. **Exercice bonus â€” Commander une pizza Dominosâ€¦ via Terraform** (simulation ğŸ˜„)

> La correction complÃ¨te se trouve dans `solution/`.

---

## Exercice 1 â€” random_pet & dÃ©pendances
Objectif : crÃ©er un nom de Â«Â petÂ Â» alÃ©atoire puis lâ€™Ã©crire dans un fichier local.
- Utilisez le provider `random` et la ressource `random_pet`.
- CrÃ©ez une dÃ©pendance logique pour Ã©crire le nom dans un fichier (`local_file`) **aprÃ¨s** la gÃ©nÃ©ration.
- Variables proposÃ©es : `prefix` (ex: *dev*), `separator` (ex: `-`).
- Sorties (`outputs`) : `pet_name`, `filename`.

CritÃ¨res dâ€™acceptation :
- `terraform init && terraform apply` crÃ©e un fichier `./dist/pet.txt` contenant le nom.
- Le nom respecte le pattern `<prefix><separator><pet>`.

---

## Exercice 2 â€” Tests & conditions
Objectif : sÃ©curiser et valider votre config.
- Ajoutez des **preconditions** et **postconditions** :
  - `prefix` non vide, `separator` âˆˆ `-` ou `_`.
  - PostconditionÂ : le contenu du fichier contient bien le nom gÃ©nÃ©rÃ©.
- Ajoutez un dossier `tests/` avec un fichier `.tftest.hcl` qui :
  - appelle le module racine avec des variables de test ;
  - **assert** que `output.pet_name` matche le bon pattern.

Commandes utiles :
```bash
terraform validate
terraform test
```

---

## Exercice 3 â€” Modules & dynamic blocks
Objectif : factoriser et gÃ©nÃ©rer plusieurs artefacts.
- CrÃ©ez un module `modules/pet_fleet` qui gÃ©nÃ¨re **N** pets et Ã©crit **N** fichiers (un par pet).
- Utilisez `for_each` et des sorties agrÃ©gÃ©es (liste des noms, liste des fichiers).
- Ajoutez un module `modules/script_runner` utilisant `terraform_data` + un **dynamic block** pour gÃ©nÃ©rer autant de `provisioner "local-exec"` que nÃ©cessaire (une commande par fichier Ã©crit).

> Remarqueâ€¯: les provisioners sont utilisÃ©s ici **uniquement** comme support pÃ©dagogique pour illustrer les `dynamic blocks`.

---

## Exercice 4 â€” Basculer sur Terragrunt (modÃ¨le GCP Library)
Objectif : rÃ©organiser votre code avec [Terragrunt](https://blog.stephane-robert.info/docs/infra-as-code/provisionnement/terragrunt/) en reprenant **la structure suivante**.

Lisez le cours suivant sur terragrunt avant de commencer : [Terragrunt](https://blog.stephane-robert.info/docs/infra-as-code/provisionnement/terragrunt/)

Structure cible (exemple)Â :
```
terragrunt/
  terragrunt.hcl                  # config root (inputs communs, generate blocks)
  live/
    dev/
      app/
        pet/terragrunt.hcl        # pointe vers ../../../../modules/pet_fleet
    prod/
      app/
        pet/terragrunt.hcl
  modules/                         # modules terraform locaux rÃ©utilisÃ©s
```

- Le **root `terragrunt.hcl`** dÃ©finit des `generate` pour crÃ©er des `provider.tf`/`backend.tf` (backend **local** dans cet atelier), et des `inputs` partagÃ©s (ex: `prefix`).
- Chaque `terragrunt.hcl` dâ€™environnement rÃ©fÃ©rence le module local via `source = "../../modules/pet_fleet"` et passe ses `inputs`.
- Commandes : `cd terragrunt/live/dev/app/pet && terragrunt run-all apply`.

Si vous avez ouvert lâ€™archive â€œGCP Library main.zipâ€, vous reconnaÃ®trez les conventions (arborescences **live/** & **modules/**, factorisation au root).

---

## Exercice 5 - Atelier â€” 3-Tier sur GCP (mockÃ©) : LB â†” VM â†” DB

ğŸ¯ Objectif : modÃ©liser une application 3-tier basique sur GCP :
rÃ©seau (VPC/Subnets/Firewall) â†’ compute (VM/App) â†’ DB (Cloud SQL) â†’ Load Balancer HTTP.
âœ… Ã€ chaque Ã©tape, vous Ã©crirez au moins un test terraform test sâ€™appuyant sur mock_provider "google", ce qui permet de tester sans crÃ©er de ressources rÃ©elles (Terraform â‰¥ 1.7 requis).Atelier â€” 3-Tier sur GCP (mockÃ©) : LB â†” VM â†” DB

Ã‰tape 1 â€” RÃ©seau : VPC, Subnet, Firewall

Ã€ faire :

	â€¢	CrÃ©er un VPC custom : google_compute_network.vpc avec auto_create_subnetworks = false.
	â€¢	CrÃ©er un Subnet rÃ©gional : google_compute_subnetwork.app (ex. 10.10.0.0/20).
	â€¢	CrÃ©er des rÃ¨gles firewall minimales :
	â€¢	allow http (80) pour le trafic entrant vers lâ€™app (via tags rÃ©seau).
	â€¢	allow ssh (22) pour lâ€™admin (optionnel).
	â€¢	(Optionnel) rÃ¨gle pour health checks (ports/IPS des HC GCP) â€” vous pouvez vous limiter au port 80 cÃ´tÃ© test.

Test obligatoire tests/01-network.tftest.hcl

  Ã‰tape 2 â€” Compute (App) : Instance Template + MIG (1)

Ã€ faire :

	â€¢	google_compute_instance_template.app (network+subnet, tag web).
	â€¢	(Optionnel) startup script qui dÃ©marre un serveur HTTP simple sur :80.
	â€¢	google_compute_region_instance_group_manager.app (target_size = 1).
	â€¢	DÃ©finir un named port http:80 pour le backend (via MIG ou instance group selon approche).

Test obligatoire tests/02-compute.tftest.hcl

Ã‰tape 3 â€” DB : Cloud SQL (mockÃ©)

Ã€ faire :

	â€¢	google_sql_database_instance.db (ex. Postgres).
	â€¢	database_version = "POSTGRES_13" (ou Ã©quivalent), settings.tier dÃ©fini.
	â€¢	google_sql_database.app (base applicative).
	â€¢	google_sql_user.app (utilisateur applicatif).

Astuce : pour rester simple (et mock-friendly), ne gÃ©rez pas le Private IP ni le Serverless VPC dans un premier temps.

Test obligatoire tests/03-db.tftest.hcl

Ã‰tape 4 â€” Load Balancer HTTP (global)

Ã€ faire (modÃ¨le classique) :

	â€¢	google_compute_health_check.http (HTTP sur / port 80).
	â€¢	google_compute_backend_service.app (protocol HTTP, health_checks, port_name = â€œhttpâ€, backend = instance group/MIG).
	â€¢	google_compute_url_map.default (default_service = backend).
	â€¢	google_compute_target_http_proxy.default (url_map).
	â€¢	google_compute_global_forwarding_rule.http (port 80, cible = proxy ; optionnel google_compute_global_address).

Test obligatoire tests/04-lb.tftest.hcl

CritÃ¨res finaux (acceptation)

	â€¢	Lâ€™architecture rÃ©seau â†’ compute â†’ db â†’ lb est dÃ©finie avec des ressources GCP cohÃ©rentes.
	â€¢	Tous les tests passent localement via terraform test sans credentials GCP (car mock_provider).
	â€¢	Les noms/labels sont paramÃ©trables (prÃ©fixes dâ€™environnement, rÃ©gion, etc.).
	â€¢	Les outputs exposent au minimum : vpc_name, subnet_name, mig_name, db_instance_name, lb_rule_name.

```
# Ã€ la racine du projet
terraform fmt -recursive
terraform validate

# Lancer tous les tests
terraform test

# Ou Ã©tape par Ã©tape
terraform test -run network_basics
terraform test -run compute_mig_minimal
terraform test -run db_basics
terraform test -run lb_http_global
```

---

## Exercice bonus â€” Commander une pizza Dominos (simulation)
Pas dâ€™API Terraform officielle pour Dominos, et pas dâ€™achats rÃ©els ici.
But pÃ©dagogique : **modÃ©liser** une ressource `pizza_order` et gÃ©nÃ©rer un **bon de commande** local (`order.json`) + une **commande shell** Ã  lancer **manuellement** (simulation).

- CrÃ©ez un module `modules/pizza_order` qui prend :
  - `store_code`, `customer`, `address`, `items` (liste dâ€™objets `{product_code, qty}`) ;
  - gÃ©nÃ¨re `order.json` via `local_file` ;
  - expose un output `curl_command` (vers une URL fictive) affichÃ© en fin dâ€™apply.
- Ajoutez des `preconditions` (quantitÃ©s > 0, items non vides).

---

## DÃ©marrage rapide
```bash
# Dans chaque exercice :
terraform init
terraform apply -auto-approve

# Tests (ex2 & suivants) :
terraform test
```

Bon apprentissage âœ¨
